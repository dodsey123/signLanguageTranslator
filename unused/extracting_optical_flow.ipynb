{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"<filenames>\"]\n",
    "input_dir = \"<input_dir>\"\n",
    "output_dir = \"<output_dir>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ca8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "def extract_tar(tar_path, extract_path):\n",
    "    # Ensure the extract path exists\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    # Open and extract the tar file\n",
    "    with tarfile.open(tar_path, 'r') as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "    return tar_path  # Returning the tar file path to update the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\taylo\\OneDrive - Queen Mary, University of London\\Documents\\BOBSL\\optical_flow\\5093521546186871869.tar.gz\n",
      "Extracting C:\\Users\\taylo\\OneDrive - Queen Mary, University of London\\Documents\\BOBSL\\optical_flow\\5093521546186871869.tar.gz\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for f in filenames:\n",
    "    # Construct the full path to the .map.gz file\n",
    "    mat_file = os.path.join(input_dir, f + '.tar.gz')\n",
    "    print(f\"Processing {mat_file}\")\n",
    "    \n",
    "    # Check if the file exists before attempting to extract it\n",
    "    if os.path.isfile(mat_file):\n",
    "        # Extract the .map.gz file to its .map counterpart in the current directory\n",
    "        print(f\"Extracting {mat_file}\")\n",
    "        extract_tar(mat_file, os.path.join(output_dir, f))\n",
    "    else:\n",
    "        print(f\"File not found: {mat_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2  # pip install opencv-python\n",
    "import torch  # pip install torch\n",
    "from tqdm import tqdm  # pip install tqdm\n",
    "\n",
    "def load_flow_sequence(\n",
    "    folder_path: str,\n",
    "    pattern: str = '*.jpg',\n",
    "    as_tensor: bool = True,\n",
    ") -> np.ndarray or torch.Tensor:\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(folder_path, pattern)))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files match {pattern} in {folder_path}\")\n",
    "\n",
    "    decoded_flows = []\n",
    "\n",
    "    for fpath in tqdm(files, desc='Decoding flow frames', unit='frame'):\n",
    "\n",
    "        bgr = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        if bgr is None:\n",
    "            raise IOError(f\"Could not read image {fpath}\")\n",
    "        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "        hsv = cv2.cvtColor((rgb * 255).astype(np.uint8), cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "        H = hsv[..., 0]           # Hue channel [0,180)\n",
    "        S = hsv[..., 1] / 255.0   # Saturation [0,1]\n",
    "\n",
    "        theta = H / 180.0 * 2.0 * np.pi\n",
    "        u = S * np.cos(theta)\n",
    "        v = S * np.sin(theta)\n",
    "\n",
    "        flow = np.stack([u, v], axis=-1).astype(np.float32)  # (H, W, 2)\n",
    "        decoded_flows.append(flow)\n",
    "\n",
    "    flows_np = np.stack(decoded_flows, axis=0)  # (T, H, W, 2)\n",
    "\n",
    "    if as_tensor:\n",
    "        return torch.from_numpy(flows_np).permute(0, 3, 1, 2)\n",
    "    else:\n",
    "        return flows_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f163a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\taylo\\OneDrive\\Documents\\Dissertation_Work\\BOBSL\\optical_flow_data\\5090916219025116054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding flow frames:  68%|██████▊   | 59451/87333 [30:14<14:10, 32.77frame/s]  \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 768. KiB for an array with shape (256, 256, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(path):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     flows \u001b[38;5;241m=\u001b[39m \u001b[43mload_flow_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded flow tensor with shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, flows\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     10\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(flows, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, f \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_optical_flow_tensor.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m, in \u001b[0;36mload_flow_sequence\u001b[1;34m(folder_path, pattern, as_tensor)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bgr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not read image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Convert RGB→HSV to extract hue (angle) & saturation (magnitude)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor((rgb \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2HSV)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 768. KiB for an array with shape (256, 256, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "for f in filenames:\n",
    "    # Construct the full path to the .map.gz file\n",
    "    path = os.path.join(dir, f)\n",
    "    \n",
    "    # Check if the file exists before attempting to extract it\n",
    "    if os.path.isdir(path):\n",
    "        print(f\"Processing {path}\")\n",
    "        flows = load_flow_sequence(path, pattern=\"*.jpg\", as_tensor=True)\n",
    "        print(\"Loaded flow tensor with shape:\", flows.shape)\n",
    "        torch.save(flows, os.path.join(output_dir, f + '_optical_flow_tensor.pt'))\n",
    "\n",
    "    else:\n",
    "        print(f\"File not found: {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
