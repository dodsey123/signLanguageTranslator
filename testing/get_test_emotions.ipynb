{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Ensure the haarcascade file is in the correct path\n",
    "cascPath = os.path.abspath(os.path.dirname(os.path.dirname(os.getcwd()))) + \"/haarcascade_frontalface_alt.xml\"\n",
    "# Check if the file exists\n",
    "if not os.path.isfile(cascPath):\n",
    "    raise FileNotFoundError(f\"File not found: {cascPath}\")\n",
    "# Load the Haar Cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "# Load the pre-trained emotion detection model\n",
    "model = load_model(\"emotion_model.keras\")\n",
    "\n",
    "# Function to process video and save frames with predictions\n",
    "def runGetImage(video_path, output_path):\n",
    "    # capture video\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    # get total frames\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # check if video opened successfully\n",
    "    if not video_capture.isOpened():\n",
    "        print(f\"Error: Cannot open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    # create empty list to store frames\n",
    "    frames = []\n",
    "\n",
    "    # loop through video frames\n",
    "    for _ in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
    "        # read frame from video\n",
    "        ret, frame = video_capture.read()\n",
    "        # check if frame is read correctly\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the frame\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        # check if any faces are detected\n",
    "        if len(faces) > 0:\n",
    "            # take the largest face detected\n",
    "            x, y, w, h = max(faces, key=lambda face: face[2] * face[3])\n",
    "            # draw rectangle around the face \n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            # resize the face to 48x48 pixels\n",
    "            face_resized = cv2.resize(face, (48, 48))\n",
    "            # normalize the pixel values to be between 0 and 1\n",
    "            face_input = face_resized.reshape(1, 48, 48, 1).astype('float32') / 255.0\n",
    "\n",
    "            # predict the emotion using the model\n",
    "            result = model.predict(face_input, verbose=0)  # shape (1, N)\n",
    "            # get the index of the class with the highest probability\n",
    "            frames.append(result[0].tolist())\n",
    "        else:\n",
    "            # if no face is detected, append an empty list\n",
    "            frames.append([])\n",
    "\n",
    "    # release the video capture object\n",
    "    video_capture.release()\n",
    "\n",
    "    # write the frames to a JSON file\n",
    "    # create the output directory if it doesn't exist\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(frames, f, indent=2)\n",
    "\n",
    "    print(f\"Finished processing {video_path}. Saved output to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the videos\n",
    "# and the output directory for the JSON files\n",
    "video_paths = \"<path_to_video_directory>\"\n",
    "output = \"<path_to_output_directory>\"\n",
    "\n",
    "# Iterate through all video files in the directory\n",
    "for v in os.listdir(video_paths):\n",
    "    # Extract the emotion data from the video and save it to a JSON file\n",
    "    runGetImage(os.path.join(video_paths,v), os.path.join(output, v[:-4] +\".json\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
