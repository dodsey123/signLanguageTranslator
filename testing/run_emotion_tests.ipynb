{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a8ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taylo\\OneDrive\\Documents\\Dissertation_Work\\signLanguageTranslator\\preprocessing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import decimal\n",
    "!pip install nltk rouge-score\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09eab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for Emotion Encoder-Decoder Transformer\n",
    "# This model is designed to process keypoints and emotion features, and generate a sequence of tokens.\n",
    "class EmotionEncoderDecoderTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_joints=25,\n",
    "                 kp_input_dim=3,\n",
    "                 emo_input_dim=7,\n",
    "                 hidden_size=256,\n",
    "                 num_layers=4,\n",
    "                 nhead=8,\n",
    "                 ff_dim=512,\n",
    "                 dropout=0.1,\n",
    "                 max_len=1024,\n",
    "                 vocab_size=30522):\n",
    "        super().__init__()\n",
    "\n",
    "        # Keypoints encoder\n",
    "        self.kp_fc = nn.Linear(num_joints * kp_input_dim, hidden_size)\n",
    "\n",
    "        # Emotions encoder\n",
    "        self.emotion_fc = nn.Linear(emo_input_dim, hidden_size)\n",
    "\n",
    "        # Emotion bias modulator for decoder\n",
    "        self.emo_to_bias = nn.Linear(emo_input_dim, hidden_size)\n",
    "\n",
    "        # Positional encoding buffer\n",
    "        pe = self._build_positional_encoding(max_len, hidden_size)\n",
    "        self.register_buffer(\"pos_encoder\", pe)  # [max_len, hidden_size]\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead,\n",
    "                                                   dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Token embedding\n",
    "        self.token_embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_size, nhead=nhead,\n",
    "                                                   dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output projection\n",
    "        self.output_fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def _build_positional_encoding(self, max_len, hidden_size):\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hidden_size, 2) * -(torch.log(torch.tensor(10000.0)) / hidden_size))\n",
    "        pe = torch.zeros(max_len, hidden_size)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe  # [max_len, hidden_size]\n",
    "\n",
    "    def forward(self, keypoints, emotions, tgt, tgt_mask=None):\n",
    "        device = keypoints.device\n",
    "\n",
    "        # Project keypoints and emotion\n",
    "        kp_feat = self.kp_fc(keypoints)           # (B, T, H)\n",
    "        emo_feat = self.emotion_fc(emotions)      # (B, T, H)\n",
    "\n",
    "        # Encoder input = keypoints + emotion bias + positional encoding\n",
    "        encoder_input = kp_feat + emo_feat\n",
    "        pos_enc = self.pos_encoder[:encoder_input.size(1)].to(device)  # (T, H)\n",
    "        encoder_input = encoder_input + pos_enc.unsqueeze(0)\n",
    "\n",
    "        # Encode\n",
    "        memory = self.encoder(encoder_input)\n",
    "\n",
    "        # Token embeddings for decoder\n",
    "        tgt_embed = self.token_embedding(tgt).to(device)\n",
    "        tgt_pos_enc = self.pos_encoder[:tgt.size(1)].to(device)\n",
    "        tgt_input = tgt_embed + tgt_pos_enc.unsqueeze(0)\n",
    "\n",
    "        # Apply emotion bias to decoder input (mean emotion across T)\n",
    "        emotion_bias = self.emo_to_bias(emotions.mean(dim=1))  # (B, H)\n",
    "        emotion_bias = emotion_bias.unsqueeze(1).expand(-1, tgt_input.size(1), -1)  # (B, T', H)\n",
    "        tgt_input = tgt_input + emotion_bias\n",
    "\n",
    "        # Decode\n",
    "        output = self.decoder(tgt_input, memory, tgt_mask=tgt_mask)\n",
    "        logits = self.output_fc(output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory containing the emotions model\n",
    "model_path = \"<path_to_model>\"\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate the model\n",
    "model = EmotionEncoderDecoderTransformer().to(device)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Load tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert subtitle times to seconds\n",
    "def time_to_float(time_str):\n",
    "\n",
    "    # Split the time string into hours, minutes, and seconds\n",
    "    hours, minutes, seconds = time_str.split(':')\n",
    "\n",
    "    # Convert to float\n",
    "    hours = float(hours)\n",
    "    minutes = float(minutes)\n",
    "    seconds = float(seconds)\n",
    "\n",
    "    # Convert to total seconds\n",
    "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "    # Return the total seconds as a float\n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files\n",
    "def load_from_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7918a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_data = load_from_json(\"<path_to_test_data>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the keypoints and emotions from JSON files\n",
    "def load_emotion_tensor_from_json(json_path, video_id):\n",
    "    # Load the JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Create a tensor for the normalised keypoints\n",
    "    normalized = []\n",
    "    # Iterate through the frames \n",
    "    for i, frame in enumerate(data):\n",
    "        # Check if the frame is empty or all zeros\n",
    "        # If so, append a zero tensor\n",
    "        if not frame or all(v == 0 for v in frame):\n",
    "            normalized.append(torch.zeros(7, dtype=torch.float32))\n",
    "        else:\n",
    "            # Convert the frame to a tensor\n",
    "            values = [float(decimal.Decimal(str(x))) for x in frame]\n",
    "            tensor = torch.tensor(values, dtype=torch.float32)\n",
    "            normalized.append(tensor)\n",
    "\n",
    "    # Convert the list of tensors to a single tensor\n",
    "    return video_id, torch.stack(normalized)  # [T, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f265064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy decoding function\n",
    "def greedy_decode(model, keypoints_tensor, emotion_tensor, tokenizer, max_len=80, start_token_id=101, end_token_id=102):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Get the device from the model parameters\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Move the tensors to the same device as the model\n",
    "    # unsqueeze the tensors to add a batch dimension\n",
    "    keypoints_tensor = keypoints_tensor.unsqueeze(0).to(device)  # [1, T, 75]\n",
    "    emotion_tensor = emotion_tensor.unsqueeze(0).to(device)      # [1, T, 7]\n",
    "    # Get the start token ID from the tokenizer\n",
    "    generated = torch.tensor([[start_token_id]], dtype=torch.long, device=device)  # [1, 1]\n",
    "\n",
    "    # Iterate for the maximum length of the sequence\n",
    "    for step in range(max_len):\n",
    "        # Generate the target mask for the decoder\n",
    "        tgt_mask = torch.nn.Transformer.generate_square_subsequent_mask(generated.size(1)).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass through the model\n",
    "            logits = model(keypoints_tensor, emotion_tensor, generated, tgt_mask=tgt_mask)\n",
    "            # Get the logits for the last token in the sequence\n",
    "            next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "            # Append the next token to the generated sequence\n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "\n",
    "        # Check if the end token is generated\n",
    "        if next_token.item() == end_token_id:\n",
    "            break\n",
    "\n",
    "    # Decode the generated sequence to text\n",
    "    return tokenizer.decode(generated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from rouge-score) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from rouge-score) (2.1.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Running Manual Tests\n",
      "\n",
      "Running Manual Tests\n",
      "\n",
      "Test Sample: 001\n",
      "Expected: Help me.\n",
      "Predicted: i ' m not a bit of the world, but it ' s not it and it ' s not a new of the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 002\n",
      "Expected: It would start to concern me a little bit, looking at five years, looking at retiring.\n",
      "Predicted: i ' m not a big, and i ' m not a little of the world.\n",
      "BLEU: 0.026012784404037925\n",
      "ROUGE: {'rouge1': Score(precision=0.14285714285714285, recall=0.125, fmeasure=0.13333333333333333), 'rougeL': Score(precision=0.14285714285714285, recall=0.125, fmeasure=0.13333333333333333)}\n",
      "\n",
      "Test Sample: 003\n",
      "Expected: Oh, God, I hate these Land Cruisers.\n",
      "Predicted: i ' ve got to be a little, but it was a little of the world, but it was, but it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.05, recall=0.14285714285714285, fmeasure=0.07407407407407408), 'rougeL': Score(precision=0.05, recall=0.14285714285714285, fmeasure=0.07407407407407408)}\n",
      "\n",
      "Test Sample: 004\n",
      "Expected: Hey, that's lovely!\n",
      "Predicted: i ' ve got to be it and you to be it ' s not a bit to be it ' s a bit.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.047619047619047616, recall=0.25, fmeasure=0.08), 'rougeL': Score(precision=0.047619047619047616, recall=0.25, fmeasure=0.08)}\n",
      "\n",
      "Test Sample: 005\n",
      "Expected: We have here two perfectly great classic soups.\n",
      "Predicted: i ' ve got to be to be to the world and the world and the world and i ' s to the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 006\n",
      "Expected: They don't want to kill us!\n",
      "Predicted: i ' ve got to be to be to the tower to the tower to the tower, and i ' ve got and i ' ve got to be you can ' ll be you can.\n",
      "BLEU: 0.005157142709886005\n",
      "ROUGE: {'rouge1': Score(precision=0.03125, recall=0.14285714285714285, fmeasure=0.05128205128205128), 'rougeL': Score(precision=0.03125, recall=0.14285714285714285, fmeasure=0.05128205128205128)}\n",
      "\n",
      "Test Sample: 007\n",
      "Expected: I'm glad you liked it.\n",
      "Predicted: i ' ve got to be a bit, and i ' ve got to be you can you can you can you can.\n",
      "BLEU: 0.008282282660969604\n",
      "ROUGE: {'rouge1': Score(precision=0.09523809523809523, recall=0.3333333333333333, fmeasure=0.14814814814814814), 'rougeL': Score(precision=0.09523809523809523, recall=0.3333333333333333, fmeasure=0.14814814814814814)}\n",
      "\n",
      "Test Sample: 008\n",
      "Expected: The most well-love bird, unmistakable.\n",
      "Predicted: i ' ve got to be to the tower to the tower to the world the world, and the tower, and the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.045454545454545456, recall=0.16666666666666666, fmeasure=0.07142857142857144), 'rougeL': Score(precision=0.045454545454545456, recall=0.16666666666666666, fmeasure=0.07142857142857144)}\n",
      "\n",
      "Test Sample: 009\n",
      "Expected: LEAVE IT!\n",
      "Predicted: you ' re a bit of the world, and you can you can ' t to be it, but it and you can you can you can you can.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.037037037037037035, recall=0.5, fmeasure=0.06896551724137931), 'rougeL': Score(precision=0.037037037037037035, recall=0.5, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Test Sample: 010\n",
      "Expected: I thought that was absolutely fascinating.\n",
      "Predicted: i ' ve got to be you to be you to be a bit to be with the tower to be with the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.043478260869565216, recall=0.16666666666666666, fmeasure=0.06896551724137931), 'rougeL': Score(precision=0.043478260869565216, recall=0.16666666666666666, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Test Sample: 011\n",
      "Expected: I expect she would be quite pleased because she did make us try and write properly, you know.\n",
      "Predicted: i ' ve got to be to the world to the world and the world and the world.\n",
      "BLEU: 0.01284618972676772\n",
      "ROUGE: {'rouge1': Score(precision=0.17647058823529413, recall=0.16666666666666666, fmeasure=0.17142857142857143), 'rougeL': Score(precision=0.17647058823529413, recall=0.16666666666666666, fmeasure=0.17142857142857143)}\n",
      "\n",
      "Test Sample: 012\n",
      "Expected: I mean, you should be annoyed at him.\n",
      "Predicted: i ' ve got to be to be to be a little, and i ' ve got to be it and i ' s not a bit to be you can ' s not it.\n",
      "BLEU: 0.0063161840849674045\n",
      "ROUGE: {'rouge1': Score(precision=0.0967741935483871, recall=0.375, fmeasure=0.15384615384615383), 'rougeL': Score(precision=0.06451612903225806, recall=0.25, fmeasure=0.10256410256410256)}\n",
      "\n",
      "Test Sample: 013\n",
      "Expected: Yes, I'm happy with that one.\n",
      "Predicted: the world, is the world, and the world, and the world, and the world, and the world and the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 014\n",
      "Expected: Well, even I can't figure this one out.\n",
      "Predicted: i ' ve got to be to be to the world and the world and the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0625, recall=0.1111111111111111, fmeasure=0.08), 'rougeL': Score(precision=0.0625, recall=0.1111111111111111, fmeasure=0.08)}\n",
      "\n",
      "Test Sample: 015\n",
      "Expected: And it's not just the tents that are worrying her.\n",
      "Predicted: the of the world of the world of the world.\n",
      "BLEU: 0.021105340631872645\n",
      "ROUGE: {'rouge1': Score(precision=0.1, recall=0.09090909090909091, fmeasure=0.09523809523809525), 'rougeL': Score(precision=0.1, recall=0.09090909090909091, fmeasure=0.09523809523809525)}\n",
      "\n",
      "Test Sample: 016\n",
      "Expected: Sorry, you'll have to excuse me.\n",
      "Predicted: i ' ve got to the tower to the world and the world and the world and the tower to the world.\n",
      "BLEU: 0.008687475782716616\n",
      "ROUGE: {'rouge1': Score(precision=0.047619047619047616, recall=0.14285714285714285, fmeasure=0.07142857142857142), 'rougeL': Score(precision=0.047619047619047616, recall=0.14285714285714285, fmeasure=0.07142857142857142)}\n",
      "\n",
      "Test Sample: 017\n",
      "Expected: A breeding colony for feathered friends.\n",
      "Predicted: i ' m not a bit to be it, and i ' ll be it ' s not a little it ' s not it ' s not a little it ' s not it ' s not it is the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.02857142857142857, recall=0.16666666666666666, fmeasure=0.048780487804878044), 'rougeL': Score(precision=0.02857142857142857, recall=0.16666666666666666, fmeasure=0.048780487804878044)}\n",
      "\n",
      "Test Sample: 018\n",
      "Expected: We all got up at 4 o'clock this morning!\n",
      "Predicted: the world, is the world, and the world, but it ' s the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 019\n",
      "Expected: This labyrinth has given me a new perspective on Neapolitans.\n",
      "Predicted: i ' ve got to be it and you can ' s a bit to be it is the world.\n",
      "BLEU: 0.009629943614188135\n",
      "ROUGE: {'rouge1': Score(precision=0.05555555555555555, recall=0.1, fmeasure=0.07142857142857142), 'rougeL': Score(precision=0.05555555555555555, recall=0.1, fmeasure=0.07142857142857142)}\n",
      "\n",
      "Test Sample: 020\n",
      "Expected: No, I'm fine but I can definitely hear something.\n",
      "Predicted: i think you can ' t you know, i think you can ' t have to have to be you know you know you know you know you know you know, you know you know you can you can you can.\n",
      "BLEU: 0.004503778123700044\n",
      "ROUGE: {'rouge1': Score(precision=0.07692307692307693, recall=0.3, fmeasure=0.12244897959183675), 'rougeL': Score(precision=0.07692307692307693, recall=0.3, fmeasure=0.12244897959183675)}\n",
      "\n",
      "Test Sample: 021\n",
      "Expected: I don't think he's going to be coming back after this.\n",
      "Predicted: the world, is the world, and the world, but it is the world................................................................\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 022\n",
      "Expected: Oh, I cannot believe how many there are.\n",
      "Predicted: i ' ve got to be you to be to be you to be to be to be to be to the tower to the tower to the tower.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.03571428571428571, recall=0.125, fmeasure=0.05555555555555556), 'rougeL': Score(precision=0.03571428571428571, recall=0.125, fmeasure=0.05555555555555556)}\n",
      "\n",
      "Test Sample: 023\n",
      "Expected: Claims about the differences between male and female brains may always be controversial but at the end of our investigation, are our views any closer?\n",
      "Predicted: i ' m not a little of the world, and i ' ve got to be to be to the world and i ' ve got to be to be.\n",
      "BLEU: 0.009337534921653758\n",
      "ROUGE: {'rouge1': Score(precision=0.18518518518518517, recall=0.2, fmeasure=0.1923076923076923), 'rougeL': Score(precision=0.14814814814814814, recall=0.16, fmeasure=0.15384615384615383)}\n",
      "\n",
      "Test Sample: 024\n",
      "Expected: You can definitely see what's going on.\n",
      "Predicted: i ' ve got to be a little of the world, and it ' s not a little of the world and it is it is a little of the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.034482758620689655, recall=0.125, fmeasure=0.05405405405405405), 'rougeL': Score(precision=0.034482758620689655, recall=0.125, fmeasure=0.05405405405405405)}\n",
      "\n",
      "Test Sample: 025\n",
      "Expected: Turner's observations of storms and dramatic skies really come together and culminate in this work...\n",
      "Predicted: i ' m not to be to be to the way, and i ' ve got to be it ' s not a bit to be it.\n",
      "BLEU: 0.006980361417366381\n",
      "ROUGE: {'rouge1': Score(precision=0.08333333333333333, recall=0.125, fmeasure=0.1), 'rougeL': Score(precision=0.041666666666666664, recall=0.0625, fmeasure=0.05)}\n",
      "\n",
      "Test Sample: 026\n",
      "Expected: Shouldn't you believe in your own ability rather than someone else's?\n",
      "Predicted: i ' m a very, but it was, i was, i ' ll be, but it was, i was, i know, i ' ll be, i ' ll be it was, i had it was, i don ' t it ' s a little it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.05128205128205128, recall=0.15384615384615385, fmeasure=0.07692307692307693), 'rougeL': Score(precision=0.05128205128205128, recall=0.15384615384615385, fmeasure=0.07692307692307693)}\n",
      "\n",
      "Test Sample: 027\n",
      "Expected: Well, it looks like he's missed all of them, actually.\n",
      "Predicted: i ' ve got to be it and it ' s a little it ' s a bit of the world and it is the world.\n",
      "BLEU: 0.008640609739997756\n",
      "ROUGE: {'rouge1': Score(precision=0.13043478260869565, recall=0.2727272727272727, fmeasure=0.1764705882352941), 'rougeL': Score(precision=0.13043478260869565, recall=0.2727272727272727, fmeasure=0.1764705882352941)}\n",
      "\n",
      "Test Sample: 028\n",
      "Expected: So there was no warnings on it, nothing of that nature.\n",
      "Predicted: i ' ve got to be a very, and i ' ve got, and i ' ve got a very, and i ' ve got a little, and i ' ll be, and i ' ll be, and i ' ve got it ' ll be it, and i ' ll be, i ' ll be, i ' ll be, and he was just it.\n",
      "BLEU: 0.003330819561259882\n",
      "ROUGE: {'rouge1': Score(precision=0.037037037037037035, recall=0.18181818181818182, fmeasure=0.061538461538461535), 'rougeL': Score(precision=0.037037037037037035, recall=0.18181818181818182, fmeasure=0.061538461538461535)}\n",
      "\n",
      "Test Sample: 029\n",
      "Expected: Would you look at that!\n",
      "Predicted: i ' ve got to be a and it ' s a and it ' s a big, and i ' s a big, and it ' s a big, and it ' s a big, and i ' s a big, and it ' s a big, and i ' s it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 030\n",
      "Expected: It's not a great result having dead lambs...\n",
      "Predicted: the world, and the world of the world and the world of the world and the world and the world and the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 031\n",
      "Expected: We don't often get much levels of aggressiveness.\n",
      "Predicted: i ' m not to be you to be you to be it, and you can you can you can you can you can you can you can you can see you can you can you can you can you can.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 032\n",
      "Expected: The battle between the wasp and the spider has been going on for a very long time and evolved into possibly the most epic battle of all.\n",
      "Predicted: i ' m not a little of the world, and i ' m not going to be a little of the world.\n",
      "BLEU: 0.010832485795226611\n",
      "ROUGE: {'rouge1': Score(precision=0.3, recall=0.2222222222222222, fmeasure=0.25531914893617025), 'rougeL': Score(precision=0.25, recall=0.18518518518518517, fmeasure=0.2127659574468085)}\n",
      "\n",
      "Test Sample: 033\n",
      "Expected: It wasn't anything to do with you!\n",
      "Predicted: i ' ve got to be it, i ' ll be it, i ' s not it, i ' s not it you can you can you can, i ' s not it.\n",
      "BLEU: 0.005648892151960285\n",
      "ROUGE: {'rouge1': Score(precision=0.10714285714285714, recall=0.375, fmeasure=0.16666666666666666), 'rougeL': Score(precision=0.07142857142857142, recall=0.25, fmeasure=0.11111111111111112)}\n",
      "\n",
      "Test Sample: 034\n",
      "Expected: I haven't handled this brilliantly, have I?\n",
      "Predicted: i can ' t you can you to be you can.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.2, recall=0.25, fmeasure=0.22222222222222224), 'rougeL': Score(precision=0.2, recall=0.25, fmeasure=0.22222222222222224)}\n",
      "\n",
      "Test Sample: 035\n",
      "Expected: This is the last place you'd expect to find sheep - look at it, there's nothing here, just sand.\n",
      "Predicted: i ' m not to be to be to the tower to be the tower to be the tower to the tower.\n",
      "BLEU: 0.010331208012220438\n",
      "ROUGE: {'rouge1': Score(precision=0.09523809523809523, recall=0.1, fmeasure=0.0975609756097561), 'rougeL': Score(precision=0.09523809523809523, recall=0.1, fmeasure=0.0975609756097561)}\n",
      "\n",
      "Test Sample: 036\n",
      "Expected: I have no idea what you're talking about.\n",
      "Predicted: i ' ve got to be to the way and the way and the world and i ' ve got to the way you can see the way you can ' t have to be.\n",
      "BLEU: 0.005311256555131655\n",
      "ROUGE: {'rouge1': Score(precision=0.09375, recall=0.3333333333333333, fmeasure=0.14634146341463417), 'rougeL': Score(precision=0.0625, recall=0.2222222222222222, fmeasure=0.0975609756097561)}\n",
      "\n",
      "Test Sample: 037\n",
      "Expected: I need another plan, cos I thought my plan was working but I need another plan.\n",
      "Predicted: i ' m not a little, but it ' s not a little, but it was just it ' s a little it was a little of the world, but it is the world.\n",
      "BLEU: 0.006510755202591488\n",
      "ROUGE: {'rouge1': Score(precision=0.0967741935483871, recall=0.1875, fmeasure=0.12765957446808507), 'rougeL': Score(precision=0.0967741935483871, recall=0.1875, fmeasure=0.12765957446808507)}\n",
      "\n",
      "Test Sample: 038\n",
      "Expected: 'But when I took a look at a map, it seems that there are some people 'who might be more in need than most.\n",
      "Predicted: the is the world, and the world, and the world, and the world, and the world and the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 039\n",
      "Expected: They would face the terror of execution and the trauma of civilian casualties.\n",
      "Predicted: i ' ve got to be to be to the world, and i ' ve got to be the world and i ' ve got to be it.\n",
      "BLEU: 0.008839374326825921\n",
      "ROUGE: {'rouge1': Score(precision=0.12, recall=0.23076923076923078, fmeasure=0.15789473684210525), 'rougeL': Score(precision=0.12, recall=0.23076923076923078, fmeasure=0.15789473684210525)}\n",
      "\n",
      "Test Sample: 040\n",
      "Expected: There was just an enormous amount of thieving going on, and sometimes it got quite violent.\n",
      "Predicted: i ' ve got to be a new, and i ' ve got to be a new to be a new of the world.\n",
      "BLEU: 0.01041441909198652\n",
      "ROUGE: {'rouge1': Score(precision=0.13636363636363635, recall=0.1875, fmeasure=0.15789473684210525), 'rougeL': Score(precision=0.09090909090909091, recall=0.125, fmeasure=0.10526315789473685)}\n",
      "\n",
      "Test Sample: 041\n",
      "Expected: People were first drawn to the Wild West in search of riches from the land.\n",
      "Predicted: i ' ve got to be to the tower to the world the tower to the world.\n",
      "BLEU: 0.026920508809559315\n",
      "ROUGE: {'rouge1': Score(precision=0.1875, recall=0.2, fmeasure=0.19354838709677422), 'rougeL': Score(precision=0.1875, recall=0.2, fmeasure=0.19354838709677422)}\n",
      "\n",
      "Test Sample: 042\n",
      "Expected: 'Plant two seeds per unit and put them somewhere warm.\n",
      "Predicted: the is the tower, the world the world, and the world, and the world.\n",
      "BLEU: 0.01428363257865929\n",
      "ROUGE: {'rouge1': Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333), 'rougeL': Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333)}\n",
      "\n",
      "Test Sample: 043\n",
      "Expected: Bar New York, there are more helicopters than any other city in the world.\n",
      "Predicted: i ' ve got to be a little, and i ' ve got to be it ' s not a little of the world.\n",
      "BLEU: 0.016734480530603443\n",
      "ROUGE: {'rouge1': Score(precision=0.09523809523809523, recall=0.14285714285714285, fmeasure=0.11428571428571427), 'rougeL': Score(precision=0.09523809523809523, recall=0.14285714285714285, fmeasure=0.11428571428571427)}\n",
      "\n",
      "Test Sample: 044\n",
      "Expected: But it's not a German vase and the material is the thing that tells us that.\n",
      "Predicted: i ' ve got to be to the way you can ' t to the tower to the tower to the tower.\n",
      "BLEU: 0.010331208012220438\n",
      "ROUGE: {'rouge1': Score(precision=0.1, recall=0.11764705882352941, fmeasure=0.1081081081081081), 'rougeL': Score(precision=0.1, recall=0.11764705882352941, fmeasure=0.1081081081081081)}\n",
      "\n",
      "Test Sample: 045\n",
      "Expected: She's stamping her foot.\n",
      "Predicted: i think you can you, you can you can you can you can you can you can you can you know you know you know you know you can you can you can you can you can you can you can you can you can you can you can you can you, you, you can you can you, you can you can you can you can you, you, you, you can you,\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 046\n",
      "Expected: This is a spy gun and it tells you the temperature of what your pan is.\n",
      "Predicted: i ' ve got to be a very, and i ' ve got to be it, and i ' ll be it was just it was just it ' s not a little it was.\n",
      "BLEU: 0.006990006728332351\n",
      "ROUGE: {'rouge1': Score(precision=0.0967741935483871, recall=0.1875, fmeasure=0.12765957446808507), 'rougeL': Score(precision=0.0967741935483871, recall=0.1875, fmeasure=0.12765957446808507)}\n",
      "\n",
      "Test Sample: 047\n",
      "Expected: Apart from the royal occasions, objects are made to commemorate all manner of events - from ship launches to moon landings to important moments in our military history.\n",
      "Predicted: i ' m a very, and i ' m a little of the world, and i ' m not a little of the world.\n",
      "BLEU: 0.007965807771672702\n",
      "ROUGE: {'rouge1': Score(precision=0.09523809523809523, recall=0.07407407407407407, fmeasure=0.08333333333333333), 'rougeL': Score(precision=0.09523809523809523, recall=0.07407407407407407, fmeasure=0.08333333333333333)}\n",
      "\n",
      "Test Sample: 048\n",
      "Expected: On top of that, a recent survey found more than half of people thought carbohydrates were fattening.\n",
      "Predicted: i ' m not a little, and i ' m not a little, and i ' ve got to be it ' s not a little of the world.\n",
      "BLEU: 0.007696339439306161\n",
      "ROUGE: {'rouge1': Score(precision=0.08, recall=0.11764705882352941, fmeasure=0.09523809523809526), 'rougeL': Score(precision=0.08, recall=0.11764705882352941, fmeasure=0.09523809523809526)}\n",
      "\n",
      "Test Sample: 049\n",
      "Expected: The Maritime Heritage Centre was started by a group of volunteers determined to preserve the city's nautical history.\n",
      "Predicted: i ' m not a little of the world, and i ' m not going to be to be to be in the world.\n",
      "BLEU: 0.011191021613657745\n",
      "ROUGE: {'rouge1': Score(precision=0.22727272727272727, recall=0.2631578947368421, fmeasure=0.24390243902439024), 'rougeL': Score(precision=0.18181818181818182, recall=0.21052631578947367, fmeasure=0.1951219512195122)}\n",
      "\n",
      "Test Sample: 050\n",
      "Expected: One hour and 20 minutes.\n",
      "Predicted: i ' ve got to be to be to the world in the world in the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 051\n",
      "Expected: The eagle-eyed cadets have spotted the kayakers, and waste no time in passing on the news.\n",
      "Predicted: i ' m a bit of the world, and you can ' t have a little of the world.\n",
      "BLEU: 0.014400124446705301\n",
      "ROUGE: {'rouge1': Score(precision=0.23529411764705882, recall=0.23529411764705882, fmeasure=0.23529411764705882), 'rougeL': Score(precision=0.17647058823529413, recall=0.17647058823529413, fmeasure=0.17647058823529413)}\n",
      "\n",
      "Test Sample: 052\n",
      "Expected: We've had a few issues with that over the past few weeks.\n",
      "Predicted: i ' m not a little, and i ' m not a little, but it was just it ' s not it was it was it ' s not a little, but it ' s not it is it is it was like it is it is it is it and it.\n",
      "BLEU: 0.003522208809549654\n",
      "ROUGE: {'rouge1': Score(precision=0.02127659574468085, recall=0.07692307692307693, fmeasure=0.03333333333333333), 'rougeL': Score(precision=0.02127659574468085, recall=0.07692307692307693, fmeasure=0.03333333333333333)}\n",
      "\n",
      "Test Sample: 053\n",
      "Expected: What's the first rule?\n",
      "Predicted: the is the world, and the world, and the world, and the world, and the world in the world.\n",
      "BLEU: 0.010182425646195498\n",
      "ROUGE: {'rouge1': Score(precision=0.05263157894736842, recall=0.2, fmeasure=0.08333333333333333), 'rougeL': Score(precision=0.05263157894736842, recall=0.2, fmeasure=0.08333333333333333)}\n",
      "\n",
      "Test Sample: 054\n",
      "Expected: Does being white make it difficult for it to hunt at night?\n",
      "Predicted: i ' ve got to be to be to be it ' s not a bit to be it and you can see it.\n",
      "BLEU: 0.01041441909198652\n",
      "ROUGE: {'rouge1': Score(precision=0.18181818181818182, recall=0.3333333333333333, fmeasure=0.23529411764705885), 'rougeL': Score(precision=0.13636363636363635, recall=0.25, fmeasure=0.1764705882352941)}\n",
      "\n",
      "Test Sample: 055\n",
      "Expected: It's not for the faint-hearted.\n",
      "Predicted: the world, the world, the world, and the world, and the world in the world in the world in the world.\n",
      "BLEU: 0.009134423666564471\n",
      "ROUGE: {'rouge1': Score(precision=0.047619047619047616, recall=0.14285714285714285, fmeasure=0.07142857142857142), 'rougeL': Score(precision=0.047619047619047616, recall=0.14285714285714285, fmeasure=0.07142857142857142)}\n",
      "\n",
      "Test Sample: 056\n",
      "Expected: There was no-one else at the time doing that type of work.\n",
      "Predicted: i ' ve got to be a very, i ' ve got, i ' ve got to be it, i think you can you can you can ' t have to be it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 057\n",
      "Expected: 'So he agreed to become one of the first 'to have a dead man's face transplanted onto his own.'\n",
      "Predicted: i ' m not a bit, and i ' ve got to be a bit, and i ' ve got to be it.\n",
      "BLEU: 0.009849349468888718\n",
      "ROUGE: {'rouge1': Score(precision=0.15, recall=0.15, fmeasure=0.15), 'rougeL': Score(precision=0.1, recall=0.1, fmeasure=0.10000000000000002)}\n",
      "\n",
      "Test Sample: 058\n",
      "Expected: What you think about the law and the police today?\n",
      "Predicted: i ' ve got to be it and it ' s a little of the world, and i ' s not it and it is it and it is the world, and it is the world.\n",
      "BLEU: 0.006787181501568368\n",
      "ROUGE: {'rouge1': Score(precision=0.09090909090909091, recall=0.3, fmeasure=0.13953488372093023), 'rougeL': Score(precision=0.09090909090909091, recall=0.3, fmeasure=0.13953488372093023)}\n",
      "\n",
      "Test Sample: 059\n",
      "Expected: But horticulture comes with small profit margins, normally between 2% and 8%, and that makes for some difficult sums if you are trying to run a business.\n",
      "Predicted: i ' m a new, and i ' ve got to be a new, and i ' ve got to the world, and i ' ve got to be, and i ' ve got, and i ' ll be, and i ' ve got to the world.\n",
      "BLEU: 0.005528849622582646\n",
      "ROUGE: {'rouge1': Score(precision=0.1, recall=0.14814814814814814, fmeasure=0.11940298507462688), 'rougeL': Score(precision=0.075, recall=0.1111111111111111, fmeasure=0.08955223880597014)}\n",
      "\n",
      "Test Sample: 060\n",
      "Expected: A relaxed-looking Lee finished the race in 59 seconds.\n",
      "Predicted: i ' m not a very, i ' m not a bit, i ' ve got, but it ' s not a bit.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.05263157894736842, recall=0.1, fmeasure=0.06896551724137931), 'rougeL': Score(precision=0.05263157894736842, recall=0.1, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Test Sample: 061\n",
      "Expected: I'm going to pop these into the greenhouse.\n",
      "Predicted: i ' ve got to be a very, and i ' ve got, and i ' ve got to be it, but it, but it ' s, and it ' s it ' s not it ' s not it ' s not it ' s a very it.\n",
      "BLEU: 0.0037447837904003834\n",
      "ROUGE: {'rouge1': Score(precision=0.05, recall=0.2222222222222222, fmeasure=0.0816326530612245), 'rougeL': Score(precision=0.05, recall=0.2222222222222222, fmeasure=0.0816326530612245)}\n",
      "\n",
      "Test Sample: 062\n",
      "Expected: I haven't got loads.\n",
      "Predicted: i ' ve got to be a and it ' s a new to be, and i ' s not a new to the way it and it ' s, and it is the way and it is the way, and i ' s a little it is the world.\n",
      "BLEU: 0.00366753025392797\n",
      "ROUGE: {'rouge1': Score(precision=0.044444444444444446, recall=0.4, fmeasure=0.07999999999999999), 'rougeL': Score(precision=0.044444444444444446, recall=0.4, fmeasure=0.07999999999999999)}\n",
      "\n",
      "Test Sample: 063\n",
      "Expected: Later on in the programme, we will be following the water course down to help breathe new life into another fine example of this restoration project.\n",
      "Predicted: i ' ve got to be to the way and i ' ve got to be to be to be to the world.........................................................\n",
      "BLEU: 0.0102805876394786\n",
      "ROUGE: {'rouge1': Score(precision=0.19047619047619047, recall=0.15384615384615385, fmeasure=0.1702127659574468), 'rougeL': Score(precision=0.14285714285714285, recall=0.11538461538461539, fmeasure=0.12765957446808512)}\n",
      "\n",
      "Test Sample: 064\n",
      "Expected: There is a debate that goes on where people like the Countryside Alliance claim that the legislation isn't being used and that it's not effective, whereas, in fact, the evidence is that it is being effective.\n",
      "Predicted: i ' m not a little, i ' m not a little, i ' m not going to be of the world.\n",
      "BLEU: 0.0060506872406626225\n",
      "ROUGE: {'rouge1': Score(precision=0.21052631578947367, recall=0.10526315789473684, fmeasure=0.14035087719298245), 'rougeL': Score(precision=0.15789473684210525, recall=0.07894736842105263, fmeasure=0.10526315789473684)}\n",
      "\n",
      "Test Sample: 065\n",
      "Expected: Curtains were never opened at any time at all, front or back of house.\n",
      "Predicted: i ' ve got to be a bit to be a bit of the world.\n",
      "BLEU: 0.013217947626377298\n",
      "ROUGE: {'rouge1': Score(precision=0.07142857142857142, recall=0.07142857142857142, fmeasure=0.07142857142857142), 'rougeL': Score(precision=0.07142857142857142, recall=0.07142857142857142, fmeasure=0.07142857142857142)}\n",
      "\n",
      "Test Sample: 066\n",
      "Expected: You go off and play, presumably.\n",
      "Predicted: i think you know, i think you can ' t it, i think it, i ' s not it was it you know, i think it was, i ' s not it, i think you don ' s not it you don ' s not it, i ' s not it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.022222222222222223, recall=0.16666666666666666, fmeasure=0.0392156862745098), 'rougeL': Score(precision=0.022222222222222223, recall=0.16666666666666666, fmeasure=0.0392156862745098)}\n",
      "\n",
      "Test Sample: 067\n",
      "Expected: Then leave them, because they won't show any signs of growth until next summer.\n",
      "Predicted: i ' ve got to be to the way and the tower to the tower to the tower to the tower.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 068\n",
      "Expected: He said so himself when he first met you.\n",
      "Predicted: i ' ve got to be you to be it, you can ' s not a bit to be it and you can you can you can you can ' t be you can you can you can see it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.02702702702702703, recall=0.1111111111111111, fmeasure=0.043478260869565216), 'rougeL': Score(precision=0.02702702702702703, recall=0.1111111111111111, fmeasure=0.043478260869565216)}\n",
      "\n",
      "Test Sample: 069\n",
      "Expected: All the juices have soaked into the rice.\n",
      "Predicted: the world, is the world, and the world, and the world in the world, and the world in the world.\n",
      "BLEU: 0.011451997463067555\n",
      "ROUGE: {'rouge1': Score(precision=0.1, recall=0.25, fmeasure=0.14285714285714288), 'rougeL': Score(precision=0.1, recall=0.25, fmeasure=0.14285714285714288)}\n",
      "\n",
      "Test Sample: 070\n",
      "Expected: Well, the condor is one of the largest flying birds in the world.\n",
      "Predicted: i ' m not you to be you to be you to be you to be to be you to be you to you to you to be you to be you, you can.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 071\n",
      "Expected: And the cubs are coping really well.\n",
      "Predicted: the of the world of the world of the world of the world of the world in the world in the world.\n",
      "BLEU: 0.008687475782716616\n",
      "ROUGE: {'rouge1': Score(precision=0.045454545454545456, recall=0.14285714285714285, fmeasure=0.06896551724137931), 'rougeL': Score(precision=0.045454545454545456, recall=0.14285714285714285, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Test Sample: 072\n",
      "Expected: But I can help you, we could take it slowly, make up our own rules...\n",
      "Predicted: i think you know, i think you can ' t have a little, i think it was just it was a very you know, but it was a little you can ' t have a little it is it is it.\n",
      "BLEU: 0.005355924989097696\n",
      "ROUGE: {'rouge1': Score(precision=0.1282051282051282, recall=0.3333333333333333, fmeasure=0.18518518518518517), 'rougeL': Score(precision=0.10256410256410256, recall=0.26666666666666666, fmeasure=0.14814814814814814)}\n",
      "\n",
      "Test Sample: 073\n",
      "Expected: Probably about the youngest oyster we sell here is about four years old.\n",
      "Predicted: i think you can ' t even to be it is the tower to be the world.\n",
      "BLEU: 0.013679192123121896\n",
      "ROUGE: {'rouge1': Score(precision=0.125, recall=0.15384615384615385, fmeasure=0.13793103448275862), 'rougeL': Score(precision=0.0625, recall=0.07692307692307693, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Test Sample: 074\n",
      "Expected: But muffled hearing isn't the only factor at play here.\n",
      "Predicted: i ' ve got to be it and it ' s a bit to be, and it ' s not a new to be it is the city to be it is the way it is the way you can.\n",
      "BLEU: 0.004620856909230222\n",
      "ROUGE: {'rouge1': Score(precision=0.02702702702702703, recall=0.09090909090909091, fmeasure=0.04166666666666667), 'rougeL': Score(precision=0.02702702702702703, recall=0.09090909090909091, fmeasure=0.04166666666666667)}\n",
      "\n",
      "Test Sample: 075\n",
      "Expected: And that leaves me with a show... a cast... ..and no theatre.\n",
      "Predicted: i ' m a very, and i ' m not a little, and i ' ve got to be a little, and i ' d been to be, and i ' d, and i ' d, and i ' d, i ' d, i ' d, and i ' d, i ' d, i ' ve got.\n",
      "BLEU: 0.0038111203719291505\n",
      "ROUGE: {'rouge1': Score(precision=0.08888888888888889, recall=0.3333333333333333, fmeasure=0.14035087719298245), 'rougeL': Score(precision=0.08888888888888889, recall=0.3333333333333333, fmeasure=0.14035087719298245)}\n",
      "\n",
      "Test Sample: 076\n",
      "Expected: We need to meet as soon as possible.\n",
      "Predicted: i ' ve got to be to the way and the world and the world and i ' ve got to the world the way you can see the way you can ' t be it.\n",
      "BLEU: 0.005157142709886005\n",
      "ROUGE: {'rouge1': Score(precision=0.030303030303030304, recall=0.125, fmeasure=0.04878048780487805), 'rougeL': Score(precision=0.030303030303030304, recall=0.125, fmeasure=0.04878048780487805)}\n",
      "\n",
      "Test Sample: 077\n",
      "Expected: Now, from sheep rustling to flytipping, the countryside certainly has its share of crime, but as Tom has been finding out, a new national survey may help to change that.\n",
      "Predicted: i ' ve got to be to the way, and you can ' t to be to be the world.\n",
      "BLEU: 0.007686998865156223\n",
      "ROUGE: {'rouge1': Score(precision=0.16666666666666666, recall=0.1, fmeasure=0.125), 'rougeL': Score(precision=0.16666666666666666, recall=0.1, fmeasure=0.125)}\n",
      "\n",
      "Test Sample: 078\n",
      "Expected: Oh, that daughter-in-law of mine's got herself free chambermaids, has she?\n",
      "Predicted: i ' m not a little, and i ' m not a little, and i ' m not going to be it was it was not a little it ' s not a little you can ' t be of the world.\n",
      "BLEU: 0.004392487796991638\n",
      "ROUGE: {'rouge1': Score(precision=0.05405405405405406, recall=0.14285714285714285, fmeasure=0.0784313725490196), 'rougeL': Score(precision=0.02702702702702703, recall=0.07142857142857142, fmeasure=0.0392156862745098)}\n",
      "\n",
      "Test Sample: 079\n",
      "Expected: She could be in there for a week before anything happens, running the risk of her damaging herself even further with minimal impact.\n",
      "Predicted: i ' m not a little, and i ' m not a little, and i ' ve got to be it ' s not a little you can ' t know, and i ' t, and i ' t, i ' t want to be you can ' t.\n",
      "BLEU: 0.004453323527690996\n",
      "ROUGE: {'rouge1': Score(precision=0.05, recall=0.08695652173913043, fmeasure=0.0634920634920635), 'rougeL': Score(precision=0.05, recall=0.08695652173913043, fmeasure=0.0634920634920635)}\n",
      "\n",
      "Test Sample: 080\n",
      "Expected: And the Georgians loved their wine, and hidden underneath this side server is the grape juice that got the party started.\n",
      "Predicted: i ' m a little of the world, and i ' m a new of the world, and i ' ve got of the world.\n",
      "BLEU: 0.011328360454400999\n",
      "ROUGE: {'rouge1': Score(precision=0.2727272727272727, recall=0.2857142857142857, fmeasure=0.2790697674418604), 'rougeL': Score(precision=0.22727272727272727, recall=0.23809523809523808, fmeasure=0.23255813953488372)}\n",
      "\n",
      "Test Sample: 081\n",
      "Expected: They are two children that I had with my first wife.\n",
      "Predicted: i ' m not a little, i ' ve got, i ' ve got, i ' ll be it, i think he was just it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.047619047619047616, recall=0.09090909090909091, fmeasure=0.0625), 'rougeL': Score(precision=0.047619047619047616, recall=0.09090909090909091, fmeasure=0.0625)}\n",
      "\n",
      "Test Sample: 082\n",
      "Expected: Before Christianity, Judaism had arrived and according to legend, this area has been the resting place for one of religion's holiest treasures for almost 3,000 years.\n",
      "Predicted: i ' m not a little of the world, and i ' ve got to be to be to the world and i ' ve got to the world.\n",
      "BLEU: 0.009152541620698935\n",
      "ROUGE: {'rouge1': Score(precision=0.15384615384615385, recall=0.14285714285714285, fmeasure=0.14814814814814817), 'rougeL': Score(precision=0.11538461538461539, recall=0.10714285714285714, fmeasure=0.11111111111111112)}\n",
      "\n",
      "Test Sample: 083\n",
      "Expected: I really rely very, very, very much on the director.\n",
      "Predicted: i ' ve got to be to be to the world.......................................................\n",
      "BLEU: 0.018850319022747353\n",
      "ROUGE: {'rouge1': Score(precision=0.2, recall=0.2, fmeasure=0.20000000000000004), 'rougeL': Score(precision=0.2, recall=0.2, fmeasure=0.20000000000000004)}\n",
      "\n",
      "Test Sample: 084\n",
      "Expected: I think it needs more pepperoni, though.\n",
      "Predicted: i can ' t you can you can have to be you can you can you have to have to be it.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.09523809523809523, recall=0.2857142857142857, fmeasure=0.14285714285714285), 'rougeL': Score(precision=0.09523809523809523, recall=0.2857142857142857, fmeasure=0.14285714285714285)}\n",
      "\n",
      "Test Sample: 085\n",
      "Expected: Um, if you go back far enough, if you go back to the 1940s and '50s, this was essentially where grey seals bred in eastern Britain.\n",
      "Predicted: i ' ve got to be to the way, and i ' ve got to be to be to the tower to the way you can.\n",
      "BLEU: 0.018272664875356538\n",
      "ROUGE: {'rouge1': Score(precision=0.16666666666666666, recall=0.15384615384615385, fmeasure=0.16), 'rougeL': Score(precision=0.125, recall=0.11538461538461539, fmeasure=0.12000000000000001)}\n",
      "\n",
      "Test Sample: 086\n",
      "Expected: And there would've been a time when you'd have understood that, or at least your wife would!\n",
      "Predicted: i ' m not a very, i think you can ' t have to be, but it, but it ' s not it you know, but it ' s not it was.\n",
      "BLEU: 0.006938247178254633\n",
      "ROUGE: {'rouge1': Score(precision=0.10714285714285714, recall=0.15789473684210525, fmeasure=0.1276595744680851), 'rougeL': Score(precision=0.10714285714285714, recall=0.15789473684210525, fmeasure=0.1276595744680851)}\n",
      "\n",
      "Test Sample: 087\n",
      "Expected: Let's think about how she got here.\n",
      "Predicted: the world, and the world, and the world, and the world, and the world, and the world in the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 088\n",
      "Expected: What do you think?\n",
      "Predicted: i ' m not a bit, but it, but it ' s not it is not it, but it you can you can you know you can you can you know, but it you can you can you can you can you can you can you can you can you can you can you can you can it.\n",
      "BLEU: 0.003148013662646501\n",
      "ROUGE: {'rouge1': Score(precision=0.017857142857142856, recall=0.25, fmeasure=0.03333333333333333), 'rougeL': Score(precision=0.017857142857142856, recall=0.25, fmeasure=0.03333333333333333)}\n",
      "\n",
      "Test Sample: 089\n",
      "Expected: Rain water seeps through the centuries-old peat before carving its way across South Devon to reach the sea.\n",
      "Predicted: i ' ve got to be to the way, and i ' ve got to be to be the world and i ' ve got to be a little to be.\n",
      "BLEU: 0.007939087147543497\n",
      "ROUGE: {'rouge1': Score(precision=0.14285714285714285, recall=0.21052631578947367, fmeasure=0.1702127659574468), 'rougeL': Score(precision=0.14285714285714285, recall=0.21052631578947367, fmeasure=0.1702127659574468)}\n",
      "\n",
      "Test Sample: 090\n",
      "Expected: It takes hours and hours and hours.\n",
      "Predicted: i ' ve got to be a bit to be a bit to be, and i ' ve got to be it and i ' s not a bit.\n",
      "BLEU: 0.007696339439306161\n",
      "ROUGE: {'rouge1': Score(precision=0.11538461538461539, recall=0.42857142857142855, fmeasure=0.18181818181818182), 'rougeL': Score(precision=0.07692307692307693, recall=0.2857142857142857, fmeasure=0.12121212121212123)}\n",
      "\n",
      "Test Sample: 091\n",
      "Expected: Last time I checked, vampires aren't big on compassion.\n",
      "Predicted: i think you can ' t even it is it you know it is not a bit to be it and it you know it you know it?\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.07407407407407407, recall=0.2, fmeasure=0.10810810810810811), 'rougeL': Score(precision=0.07407407407407407, recall=0.2, fmeasure=0.10810810810810811)}\n",
      "\n",
      "Test Sample: 092\n",
      "Expected: All across Britain at this time, a new way of life and technology emerged.\n",
      "Predicted: i ' m not a little, and i ' ve got to be a little, and i ' ve got to be it ' s not a little you can ' t think it is it is that.\n",
      "BLEU: 0.00579653593359586\n",
      "ROUGE: {'rouge1': Score(precision=0.06060606060606061, recall=0.14285714285714285, fmeasure=0.0851063829787234), 'rougeL': Score(precision=0.06060606060606061, recall=0.14285714285714285, fmeasure=0.0851063829787234)}\n",
      "\n",
      "Test Sample: 093\n",
      "Expected: Because, sometimes, talking about feelings helps to process them.\n",
      "Predicted: the world, i ' m a new, and i ' ve got to be a little, and the world, and i ' ve got to be.\n",
      "BLEU: 0.0072658577559704465\n",
      "ROUGE: {'rouge1': Score(precision=0.043478260869565216, recall=0.1111111111111111, fmeasure=0.0625), 'rougeL': Score(precision=0.043478260869565216, recall=0.1111111111111111, fmeasure=0.0625)}\n",
      "\n",
      "Test Sample: 094\n",
      "Expected: Tigers are incredibly powerful swimmers, they have these huge paws, and actually when they spread their toes out, there is webbing, if you like, in between their toes.\n",
      "Predicted: i ' ve got to be to the way, and i ' ve got to be to be a little to the world.\n",
      "BLEU: 0.006664049346323116\n",
      "ROUGE: {'rouge1': Score(precision=0.047619047619047616, recall=0.03571428571428571, fmeasure=0.04081632653061224), 'rougeL': Score(precision=0.047619047619047616, recall=0.03571428571428571, fmeasure=0.04081632653061224)}\n",
      "\n",
      "Test Sample: 095\n",
      "Expected: But the tenacious turtle fights back, and wriggles free.\n",
      "Predicted: i ' ve got to be to the tower to the tower to the tower to the tower to the tower to the tower.\n",
      "BLEU: 0.007913247271422612\n",
      "ROUGE: {'rouge1': Score(precision=0.043478260869565216, recall=0.1111111111111111, fmeasure=0.0625), 'rougeL': Score(precision=0.043478260869565216, recall=0.1111111111111111, fmeasure=0.0625)}\n",
      "\n",
      "Test Sample: 096\n",
      "Expected: So, these are the people, obviously, the people who are going to watch the runners come in at the finish line.\n",
      "Predicted: i ' m not a little, i ' m not a little, i ' ve got to be it, i think you can see it.\n",
      "BLEU: 0.007575731225158965\n",
      "ROUGE: {'rouge1': Score(precision=0.045454545454545456, recall=0.047619047619047616, fmeasure=0.046511627906976744), 'rougeL': Score(precision=0.045454545454545456, recall=0.047619047619047616, fmeasure=0.046511627906976744)}\n",
      "\n",
      "Test Sample: 097\n",
      "Expected: They're the wonders of the age.\n",
      "Predicted: i ' ve got to be a and it ' s a little, and i ' s not a little of the world and i ' s a little it ' s not it ' s not it and it is in the way, and it and i ' s a little it and i ' s it and it.\n",
      "BLEU: 0.007115473177343403\n",
      "ROUGE: {'rouge1': Score(precision=0.057692307692307696, recall=0.42857142857142855, fmeasure=0.10169491525423728), 'rougeL': Score(precision=0.038461538461538464, recall=0.2857142857142857, fmeasure=0.06779661016949154)}\n",
      "\n",
      "Test Sample: 098\n",
      "Expected: They were allowed to freely roam around.\n",
      "Predicted: the is the tower, the world the world and the world and the world and the world and the world and the world the world.\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Test Sample: 099\n",
      "Expected: I want to say something else about the castle.\n",
      "Predicted: i was a, i was, i was, i was just, i was just, i was just it, i was a little it was, but it was, but it was, i was, i was, i don ' t it was just it he was a little, but it he, but it, but it, but it, but it he was, but it he, but\n",
      "BLEU: 0\n",
      "ROUGE: {'rouge1': Score(precision=0.01639344262295082, recall=0.1111111111111111, fmeasure=0.028571428571428574), 'rougeL': Score(precision=0.01639344262295082, recall=0.1111111111111111, fmeasure=0.028571428571428574)}\n",
      "\n",
      "Test Sample: 100\n",
      "Expected: And, there, he attacked the temple establishment, overturning the tables of the money changers and telling them they had turned God's house into a den of thieves.\n",
      "Predicted: i ' m not a very, and i ' m not a little, and i ' m not a little of the world.\n",
      "BLEU: 0.017503930122526722\n",
      "ROUGE: {'rouge1': Score(precision=0.25, recall=0.17857142857142858, fmeasure=0.20833333333333331), 'rougeL': Score(precision=0.2, recall=0.14285714285714285, fmeasure=0.16666666666666666)}\n",
      "\n",
      "Average BLEU: 0.0061\n",
      "Average ROUGE-1: 0.0965\n",
      "Average ROUGE-L: 0.0859\n"
     ]
    }
   ],
   "source": [
    "# Run manual tests\n",
    "print(\"Running Manual Tests\")\n",
    "\n",
    "# Paths to the emotion data and keypoints\n",
    "test_keypoints_dir = \"<path_to_test_keypoints>\"\n",
    "test_emotions_dir = \"<path_to_test_emotions>\"\n",
    "# Load the test metadata\n",
    "fps = 25\n",
    "num_joints = 25\n",
    "keypoints_dim = num_joints * 3\n",
    "\n",
    "# Create a list to store the processed test samples\n",
    "processed_test_samples = []\n",
    "\n",
    "# Iterate through the test data\n",
    "for data in test_data:\n",
    "    # Extract the code and subtitle text from the data\n",
    "    code = data[\"code\"]\n",
    "    subtitle_text = data[\"text\"]\n",
    "    \n",
    "    # Build the path to the keypoints file\n",
    "    keypoints_path = os.path.join(test_keypoints_dir, code + \"_keypoints.pt\")\n",
    "    # Check if the keypoints file exists\n",
    "    if not os.path.exists(keypoints_path):\n",
    "        print(f\"[Warning] Keypoints file not found for {code}\")\n",
    "        continue\n",
    "\n",
    "    # Load the keypoints tensor\n",
    "    full_keypoints = torch.load(keypoints_path)\n",
    "\n",
    "    # Check if the keypoints tensor is empty\n",
    "    if len(full_keypoints) == 0:\n",
    "        print(f\"[Warning] Skipping {code}: empty keypoints\")\n",
    "        continue\n",
    "    \n",
    "    # Process the keypoints tensor\n",
    "    processed_kps = []\n",
    "    # Iterate through the frames in the keypoints tensor\n",
    "    for frame in full_keypoints:\n",
    "        # Create a tensor for the keypoints in the current frame\n",
    "        frame_tensor = torch.zeros(keypoints_dim)\n",
    "        # Check if the frame is empty\n",
    "        if len(frame) > 0:\n",
    "            # Get the first person in the frame\n",
    "            person = frame[0]\n",
    "            # Flatten the keypoints for the first person\n",
    "            flat_kps = [coord for part in person for joint in part for coord in joint]\n",
    "            flat_kps = flat_kps[:keypoints_dim] + [0] * max(0, keypoints_dim - len(flat_kps))\n",
    "            # Create a tensor for the flattened keypoints\n",
    "            frame_tensor = torch.tensor(flat_kps[:keypoints_dim], dtype=torch.float32)\n",
    "        # Append the frame tensor to the list of processed keypoints\n",
    "        processed_kps.append(frame_tensor)\n",
    "\n",
    "    # Convert the list of processed keypoints to a tensor\n",
    "    keypoints_tensor = torch.stack(processed_kps)  # [T, 75]\n",
    "\n",
    "    # Load the emotion tensor\n",
    "    _, emotion_tensor = load_emotion_tensor_from_json(os.path.join(test_emotions_dir, code + \"_edited.json\"), code + \"_edited.json\")\n",
    "    # Check if the emotion tensor is the right size\n",
    "    if emotion_tensor.size(0) != keypoints_tensor.size(0):\n",
    "        # If not, truncate the longer tensor to the length of the shorter one\n",
    "        min_len = min(emotion_tensor.size(0), keypoints_tensor.size(0))\n",
    "        emotion_tensor = emotion_tensor[:min_len]\n",
    "        keypoints_tensor = keypoints_tensor[:min_len]\n",
    "\n",
    "    # Add the processed sample to the list\n",
    "    processed_test_samples.append((keypoints_tensor, emotion_tensor, subtitle_text, code))\n",
    "\n",
    "# Initialize the values for BLEU and ROUGE scores\n",
    "smooth_fn = SmoothingFunction().method1\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "all_bleu_scores = []\n",
    "all_rouge_scores = []\n",
    "\n",
    "print(\"\\nRunning Manual Tests\")\n",
    "# Iterate through the processed test samples\n",
    "for keypoints, emotions, expected_text, code in processed_test_samples:\n",
    "    print(f\"\\nTest Sample: {code}\")\n",
    "    print(\"Expected:\", expected_text)\n",
    "\n",
    "    # Get the predicted text using greedy decoding\n",
    "    result = greedy_decode(model, keypoints, emotions, tokenizer)\n",
    "    print(\"Predicted:\", result)\n",
    "\n",
    "    # BLEU\n",
    "    ref_tokens = [expected_text.split()]\n",
    "    gen_tokens = result.split()\n",
    "    bleu = sentence_bleu(ref_tokens, gen_tokens, smoothing_function=smooth_fn)\n",
    "    all_bleu_scores.append(bleu)\n",
    "    print(\"BLEU:\", bleu)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = scorer.score(expected_text, result)\n",
    "    all_rouge_scores.append(rouge)\n",
    "    print(\"ROUGE:\", rouge)\n",
    "\n",
    "# Get the average BLEU and ROUGE scores\n",
    "avg_bleu = sum(all_bleu_scores) / len(all_bleu_scores)\n",
    "avg_rouge1 = sum(r['rouge1'].fmeasure for r in all_rouge_scores) / len(all_rouge_scores)\n",
    "avg_rougeL = sum(r['rougeL'].fmeasure for r in all_rouge_scores) / len(all_rouge_scores)\n",
    "\n",
    "# Print the average scores\n",
    "print(f\"\\nAverage BLEU: {avg_bleu:.4f}\")\n",
    "print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
