{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.layers import Input,Activation,Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the dataset directory\n",
    "input_dir = \"<path_to_dataset>\"\n",
    "files = os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folder names as labels and images underneath\n",
    "i=0\n",
    "last=[]\n",
    "images=[]\n",
    "labels=[]\n",
    "temp = input_dir\n",
    "\n",
    "# Read folders in the main dataset folder, one at a time\n",
    "for files in input_dir:\n",
    "  sub_folder_index = temp.index(files)\n",
    "  label = sub_folder_index\n",
    "\n",
    "  path = input_dir+'/'+sub_folder\n",
    "  sub_folder_images= os.listdir(path)\n",
    "\n",
    "  # Read images in the sub folder, one at a time\n",
    "  for image in sub_folder_images:\n",
    "    image_path = path+'/'+image\n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image= cv2.resize(image,(48,48))\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "    i+=1\n",
    "  last.append(i)\n",
    "\n",
    "# Declare x and y\n",
    "images_x = np.array(images)\n",
    "labels_y = np.array(labels)\n",
    "# We divide image pixels by 255 to reduce computation power\n",
    "images_x = images_x/255\n",
    "\n",
    "# encoding the labels\n",
    "num_of_classes = 7\n",
    "labels_y_encoded = tf.keras.utils.to_categorical(labels_y,num_classes=num_of_classes)\n",
    "\n",
    "# Split into 75:25 train and test\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(images_x, labels_y_encoded,test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture\n",
    "# Define the dropout rate\n",
    "dropout_rate = 0.1\n",
    "# Define the L2 regularization rate\n",
    "l2_rate = 0.001\n",
    "# Input Layer Of 48x48 pixels\n",
    "input = Input(shape = (48,48,1))\n",
    "# Convolutional Layer with 32 filters of size 3x3, with L2 regularization\n",
    "conv_1 = Conv2D(32,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(l2_rate))(input)\n",
    "# Dropout Layer with 0.1 dropout rate\n",
    "conv_1 = Dropout(dropout_rate)(conv_1)\n",
    "# Activation Layer with ReLU activation function\n",
    "conv_1 = Activation('relu')(conv_1)\n",
    "# MaxPooling Layer with 2x2 pool size\n",
    "pool_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
    "# Convolutional Layer with 64 filters of size 3x3, with L2 regularization\n",
    "conv_2 = Conv2D(64,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(l2_rate))(pool_1)\n",
    "# Dropout Layer with 0.1 dropout rate\n",
    "conv_2 = Dropout(dropout_rate)(conv_2)\n",
    "# Activation Layer with ReLU activation function\n",
    "conv_2 = Activation('relu')(conv_2)\n",
    "# MaxPooling Layer with 2x2 pool size\n",
    "pool_2 = MaxPooling2D(pool_size = (2,2)) (conv_2)\n",
    "# Convolutional Layer with 128 filters of size 3x3, with L2 regularization\n",
    "conv_3 = Conv2D(128,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(l2_rate))(pool_2)\n",
    "# Dropout Layer with 0.1 dropout rate\n",
    "conv_3 = Dropout(dropout_rate)(conv_3)\n",
    "# Activation Layer with ReLU activation function\n",
    "conv_3 = Activation('relu')(conv_3)\n",
    "# MaxPooling Layer with 2x2 pool size\n",
    "pool_3 = MaxPooling2D(pool_size = (2,2)) (conv_3)\n",
    "# Convolutional Layer with 256 filters of size 3x3, with L2 regularization\n",
    "conv_4 = Conv2D(256,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(l2_rate))(pool_3)\n",
    "# Dropout Layer with 0.1 dropout rate\n",
    "conv_4 = Dropout(dropout_rate)(pool_3)\n",
    "# Activation Layer with ReLU activation function\n",
    "conv_4 = Activation('relu')(conv_4)\n",
    "# MaxPooling Layer with 2x2 pool size\n",
    "pool_4 = MaxPooling2D(pool_size = (2,2)) (conv_4)\n",
    "# Flatten Layer to convert 3D matrix to 1D vector\n",
    "flatten = Flatten()(pool_4)\n",
    "# Relu Layer with 128 neurons\n",
    "dense_1 = Dense(128,activation='relu')(flatten)\n",
    "# Dropout Layer with 0.2 dropout rate\n",
    "drop_1 = Dropout(dropout_rate *2)(dense_1)\n",
    "# Sigmoid Layer with 7 neurons for 7 classes\n",
    "output = Dense(7,activation=\"sigmoid\")(drop_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=input,outputs=output)\n",
    "# Adams optimizer with learning rate of 0.001\n",
    "# Categorical crossentropy loss function\n",
    "model.compile(optimizer=\"adam\", loss=[\"categorical_crossentropy\"], metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Model Checkpoint\n",
    "file_path='./output/emotion_model.keras'\n",
    "# Save the model after every epoch\n",
    "checkpointer = ModelCheckpoint(file_path, monitor='loss',verbose=1,save_best_only=True,\n",
    "                               save_weights_only=False, mode='auto',save_freq='epoch')\n",
    "# Set the callback list to include the checkpointer\n",
    "callback_list=[checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Fit the model with training data, validation data, and the callback list\n",
    "save = model.fit(X_train,Y_train,batch_size=32,validation_data=(X_test,Y_test),epochs=50,callbacks=[callback_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the train and test loss and accuracy values from the neural network above.\n",
    "train_loss = save.history['loss']\n",
    "test_loss = save.history['val_loss']\n",
    "train_accuracy = save.history['accuracy']\n",
    "test_accuracy = save.history['val_accuracy']\n",
    "\n",
    "# Plotting a line chart to visualize the loss and accuracy values by epochs.\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15,7))\n",
    "ax = ax.ravel()\n",
    "ax[0].plot(train_loss, label='Train Loss', color='royalblue', marker='o', markersize=5)\n",
    "ax[0].plot(test_loss, label='Test Loss', color = 'orangered', marker='o', markersize=5)\n",
    "ax[0].set_xlabel('Epochs', fontsize=14)\n",
    "ax[0].set_ylabel('Categorical Crossentropy', fontsize=14)\n",
    "ax[0].legend(fontsize=14)\n",
    "ax[0].tick_params(axis='both', labelsize=12)\n",
    "ax[1].plot(train_accuracy, label='Train Accuracy', color='royalblue', marker='o', markersize=5)\n",
    "ax[1].plot(test_accuracy, label='Test Accuracy', color='orangered', marker='o', markersize=5)\n",
    "ax[1].set_xlabel('Epochs', fontsize=14)\n",
    "ax[1].set_ylabel('Accuracy', fontsize=14)\n",
    "ax[1].legend(fontsize=14)\n",
    "ax[1].tick_params(axis='both', labelsize=12)\n",
    "fig.suptitle(x=0.5, y=0.92, t=\"Lineplots showing loss and accuracy of CNN model by epochs\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model.save('./output/emotion_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
