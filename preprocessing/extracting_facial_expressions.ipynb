{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\taylo\\onedrive\\documents\\dissertation_work\\signlanguagetranslator\\preprocessing\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Ensure the haarcascade file is in the correct path\n",
    "cascPath = os.path.abspath(os.path.dirname(os.path.dirname(os.getcwd()))) + \"/haarcascade_frontalface_alt.xml\"\n",
    "# Check if the file exists\n",
    "if not os.path.isfile(cascPath):\n",
    "    raise FileNotFoundError(f\"File not found: {cascPath}\")\n",
    "# Load the Haar Cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "# Load the pre-trained emotion detection model\n",
    "model = load_model(\"emotion_model.keras\")\n",
    "\n",
    "# Function to process video and save frames with predictions\n",
    "def runGetImage(video_path, output_path):\n",
    "    # capture video\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    # get total frames\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # check if video opened successfully\n",
    "    if not video_capture.isOpened():\n",
    "        print(f\"Error: Cannot open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    # create empty list to store frames\n",
    "    frames = []\n",
    "\n",
    "    # loop through video frames\n",
    "    for _ in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
    "        # read frame from video\n",
    "        ret, frame = video_capture.read()\n",
    "        # check if frame is read correctly\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the frame\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        # check if any faces are detected\n",
    "        if len(faces) > 0:\n",
    "            # take the largest face detected\n",
    "            x, y, w, h = max(faces, key=lambda face: face[2] * face[3])\n",
    "            # draw rectangle around the face \n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            # resize the face to 48x48 pixels\n",
    "            face_resized = cv2.resize(face, (48, 48))\n",
    "            # normalize the pixel values to be between 0 and 1\n",
    "            face_input = face_resized.reshape(1, 48, 48, 1).astype('float32') / 255.0\n",
    "\n",
    "            # predict the emotion using the model\n",
    "            result = model.predict(face_input, verbose=0)  # shape (1, N)\n",
    "            # get the index of the class with the highest probability\n",
    "            frames.append(result[0].tolist())\n",
    "        else:\n",
    "            # if no face is detected, append an empty list\n",
    "            frames.append([])\n",
    "\n",
    "    # release the video capture object\n",
    "    video_capture.release()\n",
    "\n",
    "    # write the frames to a JSON file\n",
    "    # create the output directory if it doesn't exist\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(frames, f, indent=2)\n",
    "\n",
    "    print(f\"Finished processing {video_path}. Saved output to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing file for video:  5086465773912997411.mp4  counter =  1\n",
      "Found existing file for video:  5087953980081062580.mp4  counter =  2\n",
      "Found existing file for video:  5090546422340930233.mp4  counter =  3\n",
      "Found existing file for video:  5090916219025116054.mp4  counter =  4\n",
      "Found existing file for video:  5092765202446045704.mp4  counter =  5\n",
      "Found existing file for video:  5093160768934007504.mp4  counter =  6\n",
      "Found existing file for video:  5093521546186871869.mp4  counter =  7\n",
      "Found existing file for video:  5093895208341624036.mp4  counter =  8\n",
      "Found existing file for video:  5094257274914886988.mp4  counter =  9\n",
      "Found existing file for video:  5097975856769557081.mp4  counter =  10\n",
      "Found existing file for video:  5099091689273058848.mp4  counter =  11\n",
      "Found existing file for video:  5099449889545545450.mp4  counter =  12\n",
      "Found existing file for video:  5101325932090649776.mp4  counter =  13\n",
      "Found existing file for video:  5103182645622502287.mp4  counter =  14\n",
      "Found keypoints file for video:  5104636062555440832.mp4  counter =  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 89464/89464 [1:44:25<00:00, 14.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released video file: D:\\original_data\\5104636062555440832.mp4\n",
      "Saved results to C:\\Users\\taylo\\OneDrive\\Documents\\Dissertation_Work\\BOBSL\\FED_output_data\\5104636062555440832.json (JSON Lines format)\n",
      "Found existing file for video:  5105777664862718183.mp4  counter =  16\n",
      "Found existing file for video:  5106137153625393471.mp4  counter =  17\n",
      "Found existing file for video:  5108723153434317714.mp4  counter =  18\n",
      "Found existing file for video:  5113588492387230304.mp4  counter =  19\n",
      "Found existing file for video:  5120215198258444599.mp4  counter =  20\n",
      "Found existing file for video:  5125058632047937012.mp4  counter =  21\n",
      "Found existing file for video:  5129558040617440365.mp4  counter =  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "video_paths = \"<path_to_video_files>\"\n",
    "keypoints_path = \"<path_to_keypoints_files>\"\n",
    "output = \"<path_to_output_json>\"\n",
    "\n",
    "# read video files and keypoints files\n",
    "keypoints_files = glob(os.path.join(keypoints_path, \"*_keypoints.pth\"))\n",
    "existing_files = glob(os.path.join(output, \"*.json\"))\n",
    "\n",
    "counter = 0\n",
    "skip = False\n",
    "\n",
    "# list all video files in the directory\n",
    "for v in os.listdir(video_paths):\n",
    "    # list all video files in the existing files list\n",
    "    for e in existing_files:\n",
    "        # build the base name of the existing file\n",
    "        base_name = os.path.basename(e).replace(\".json\", \"\")\n",
    "        # check if the video file name matches the existing file name\n",
    "        if (v[:-4] == base_name):\n",
    "            # increment the counter and print the message\n",
    "            counter += 1\n",
    "            print(\"Found existing file for video: \", v, \" counter = \", counter)\n",
    "            skip = True\n",
    "            break\n",
    "    # if skip is True, continue to the next iteration\n",
    "    if skip:\n",
    "        skip = False\n",
    "        continue\n",
    "    # if skip is False, check for keypoints files\n",
    "    for k in keypoints_files:\n",
    "        # build the base name of the keypoints file\n",
    "        base_name = os.path.basename(k).replace(\"_keypoints.pth\", \"\")\n",
    "        # check if the keypoints file name matches the video file name\n",
    "        if (v[:-4] == base_name):\n",
    "            # increment the counter and print the message\n",
    "            counter += 1\n",
    "            print(\"Found keypoints file for video: \", v, \" counter = \", counter)\n",
    "            # call the runGetImage function to process the video and save the frames with predictions\n",
    "            runGetImage(os.path.join(video_paths,v), os.path.join(output, v[:-4] +\".json\"))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
